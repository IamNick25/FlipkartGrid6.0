from PIL import Image
import cv2
import time
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import pyplot as plt
import cv2
import time
from easyocr import Reader
from pylab import rcParams
from IPython.display import Image
import pandas as pd
import numpy as np
from skimage.filters import threshold_local
from groq import Groq
import tkinter as tk
from tkinter import filedialog, messagebox
from PIL import  Image,ImageTk
from tensorflow.keras.preprocessing.image import load_img, img_to_array



def imshow(title="Image", image=None, size=10):
    w, h = image.shape[0], image.shape[1]
    aspect_ratio = w / h
    plt.figure(figsize=(size * aspect_ratio, size))
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    plt.title(title)
    plt.show()





# Placeholder for your trained model functions
def check_ripeness(image_path):
    
    class_labels = ['fresh_apple', 'fresh_banana', 'fresh_bitter_gourd', 'fresh_capsicum', 'fresh_orange', 'fresh_tomato',
              'stale_apple', 'stale_banana', 'stale_bitter_gourd', 'stale_capsicum', 'stale_orange', 'stale_tomato']
    IMG_HEIGHT = 227
    IMG_WIDTH = 227
    # Function to preprocess and predict on a new image
    # Load the image and resize it to match the input shape expected by the model
    new_image=load_img(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    model=tf.keras.models.load_model("D:\Downloads\FruitFreshness.h5")
    # Convert the image to array format (Tensor)
    new_image=img_to_array(new_image)

    # Normalize the image
    new_image=new_image / 255.0


    new_image=np.expand_dims(new_image, axis=0)  # Shape: (1, IMG_HEIGHT, IMG_WIDTH, 3)


    prediction=model.predict(new_image)

    predicted_class=tf.argmax(prediction, axis=1)
    predicted_label=class_labels[predicted_class[0]]
    plt.imshow(load_img(image_path))
    plt.title(f"Predicted Class: {predicted_label}")
    plt.axis('off')
    plt.show()

    return predicted_label




def check_defects(image_path):
    def load_image(image_path):
        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
        if image is None:
            raise ValueError("Image not found or unable to load!")
        return image

    def apply_gabor_filter(image, num_scales=4, num_orientations=6):
        gabor_images = []

        # Generate Gabor kernels for different scales and orientations
        for scale in range(1, num_scales + 1):
            for theta in range(num_orientations):
                theta_rad = theta * np.pi / num_orientations
                kernel = cv2.getGaborKernel((21, 21), sigma=4.0, theta=theta_rad, lambd=10.0/scale, gamma=0.5, psi=0)
                filtered_image = cv2.filter2D(image, cv2.CV_8UC3, kernel)
                gabor_images.append(filtered_image)

        # Combine all Gabor-filtered images
        combined_gabor = np.maximum.reduce(gabor_images)
        return combined_gabor

# Detect tears based on Gabor filter (edge detection on Gabor-filtered output)
    def detect_tear_gabor(gabor_image, edge_threshold=100):
        # Apply edge detection (Canny) to the Gabor filtered image
        edges = cv2.Canny(gabor_image, threshold1=edge_threshold, threshold2=edge_threshold * 2)

        # Check if a significant number of edges are detected (indicating a tear)
        edge_density = np.sum(edges) / edges.size
        if edge_density > 0.05:  # Heuristic threshold
            return True  # Potential tear detected
        return False


# Plot results
    def plot_results(original, gabor):
        fig, ax = plt.subplots(1, 3, figsize=(15, 5))

        # Original Image
        ax[0].imshow(original, cmap='gray')
        ax[0].set_title('Original Image')
        ax[0].axis('off')


        # Gabor Filtered Image
        ax[1].imshow(gabor, cmap='gray')
        ax[1].set_title('Gabor Filtered Image')
        ax[1].axis('off')

        plt.show()

# Main function
    def process_image(image_path):
        # Load the image
        image = load_image(image_path)

        # Apply Local Binary Pattern (LBP)


        # Apply Gabor Filters
        gabor_image = apply_gabor_filter(image)

        tear_detected = detect_tear_gabor(gabor_image)

        # Print results
        if tear_detected:
            
            return "Defected"
        else:
            
            return "Non defected"



# Example usage:
    
    return process_image(image_path)
    
    
    

def extract_product_details(image_path):
    # PERSPECTIVE TRANSFORM OF THE CAPTURED IMAGE

    image = cv2.imread(image_path)
    image2 = cv2.imread(image_path)
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    _, th = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    # imshow("Original",image)
    # imshow("Threshold",th)

    contours, hierarchy = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cv2.drawContours(image, contours, -1, (0, 255, 0), thickness=2)
    # imshow("Contours",image)
    # print(str(len(contours)))

    sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)

    min_x = float('inf')
    max_x = float('-inf')
    min_y = float('inf')
    max_y = float('-inf')
    for cnt in sorted_contours:
        x, y, w, h = cv2.boundingRect(cnt)
        min_x = min(min_x, x)
        max_x = max(max_x, x + w)
        min_y = min(min_y, y)
        max_y = max(max_y, y + h)

    # print(f"Overall bounding box - min_x:{min_x},max_x:{max_x},min_y:{min_y},max_y:{max_y}")
    cv2.rectangle(image, (min_x, min_y), (max_x, max_y), (0, 255, 0), 2)
    cropped_image = image2[min_y:max_y, min_x:max_x]
    # cv2_imshow(cropped_image)
    # cv2.waitKey(0)
    reader = Reader(['en'], gpu=False)
    start = time.time()
    result = reader.readtext(cropped_image)
    end = time.time()
    time_taken = end - start
    print(f"Time Taken: {time_taken}")

    recognized_text = [item[1] for item in result]
    # print(recognized_text)
    '''for text in recognized_text:
      print(f"{text}")'''
    final_text = " ".join(recognized_text)
    # print(final_text)
    # print(result)

    GROQ_API_KEY = "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"
    client = Groq(api_key=GROQ_API_KEY) 
    completion = client.chat.completions.create(
        model="llama3-8b-8192",
        messages=[{"role": "user",
                   "content": f"Organize and clean up the following text into a proper readable format with appropriate sections:\n\n{final_text}"}],
        temperature=1,
        max_tokens=1024,
        top_p=1,
        stream=True,
        stop=None,
    )
    response = ""
    for chunk in completion:
        response += chunk.choices[0].delta.content or ""
        # print(x)

    return response


# Function to handle the processing based on user's choice
def process_image(option, image_path):
    result = ""
    image_path = "captured_image.jpg"
    if option == "Ripeness":
        result = check_ripeness(image_path)
    elif option == "Defects":
        result = check_defects(image_path)
    elif option == "Product Details":
        result = extract_product_details(image_path)

    # Display result in the UI and save to text file
    text_area.delete(1.0, tk.END)  # Clear the text area first
    text_area.insert(tk.END, result)

    # Save result to a text file
    with open("product_analysis_output.txt", "w") as file:
        file.write(result)

    messagebox.showinfo("Success", "Analysis completed and saved to product_analysis_output.txt")


# Function to load an image from file
def load_image():
    global img, img_tk, image_path
    image_path = filedialog.askopenfilename(filetypes=[("Image Files", ".jpg;.jpeg;.png;.bmp;*.tiff")])
    if image_path:
        img = Image.open(image_path)
        img.thumbnail((250, 250))  # Resize to fit the UI
        img_tk = ImageTk.PhotoImage(img)
        image_label.config(image=img_tk)
        image_label.image = img_tk  # Keep a reference of the image
        img.save("captured_image.png", format="PNG")


# Function to capture an image from the camera
def capture_image():
    global img, img_tk, image_path
    cam = cv2.VideoCapture(0)  # Open the camera
    cv2.namedWindow("Capture Image")

    while True:
        ret, frame = cam.read()  # Read the frame
        if not ret:
            print("Failed to grab frame")
            break
        cv2.imshow("Capture Image", frame)

        # Press 'SPACE' to capture and 'ESC' to exit
        k = cv2.waitKey(1)
        if k % 256 == 27:  # ESC pressed
            print("Escape hit, closing...")
            break
        elif k % 256 == 32:  # SPACE pressed
            image_path = "captured_image.jpg"
            cv2.imwrite(image_path, frame)
            print(f"Image captured and saved as {image_path}")
            break

    cam.release()
    cv2.destroyAllWindows()

    # Load the captured image in the UI
    img = Image.open(image_path)
    img.thumbnail((250, 250))  # Resize to fit the UI
    img_tk = ImageTk.PhotoImage(img)
    image_label.config(image=img_tk)
    image_label.image = img_tk  # Keep a reference of the image


# Function to handle the "Submit" button click
def submit_choice():
    selected_option = option_var.get()

    # Check for missing image
    if not 'image_path' in globals() or not image_path:
        messagebox.showerror("Error", "Please upload or capture an image first.")
    elif selected_option == "None":
        messagebox.showerror("Error", "Please select a valid analysis option.")
    else:
        process_image(selected_option, image_path)


# Create the main window
root = tk.Tk()
root.title("Flipkart-Themed Product Image Analysis")
root.geometry("450x600")

# Set the background color to match Flipkart's theme (blue)
root.config(bg='#2874F0')

# Customize fonts and colors for Flipkart theme
heading_font = ("Arial", 16, "bold")
label_font = ("Arial", 12)
button_font = ("Arial", 12, "bold")

# Label for instructions with Flipkart colors
instructions = tk.Label(root, text="Upload or capture a product image and choose an analysis option:",
                        bg='#2874F0', fg="white", font=heading_font)
instructions.pack(pady=10)

# Button to load the image from file with Flipkart yellow color
load_button = tk.Button(root, text="Load Image", command=load_image,
                        bg="#FFB740", fg="black", font=button_font)
load_button.pack(pady=10)

# Button to capture the image from camera with Flipkart yellow color
capture_button = tk.Button(root, text="Capture Image", command=capture_image,
                           bg="#FFB740", fg="black", font=button_font)
capture_button.pack(pady=10)

# Label to display the loaded or captured image
image_label = tk.Label(root, bg='#2874F0')
image_label.pack(pady=10)

# Dropdown menu for selecting the analysis type, including 'None'
option_var = tk.StringVar(root)
option_var.set("None")  # Set 'None' as the default option
options = ["None", "Ripeness", "Defects", "Product Details"]
option_menu = tk.OptionMenu(root, option_var, *options)
option_menu.config(bg="#FFB740", fg="black", font=label_font, width=20)
option_menu.pack(pady=10)

# Submit button to perform analysis
submit_button = tk.Button(root, text="Submit", command=submit_choice,
                          bg="#FFB740", fg="black", font=button_font)
submit_button.pack(pady=20)

# Text area to display the result
text_area = tk.Text(root, height=10, width=40, bg="white", fg="black", font=label_font)
text_area.pack(pady=20)

# Run the main event loop
root.mainloop()
